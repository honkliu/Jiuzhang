{
  "id": "qwen-edit-optimized-fast",
  "revision": 0,
  "last_node_id": 161,
  "last_link_id": 331,
  "nodes": [
    {
      "id": 41,
      "type": "LoadImage",
      "pos": [-2820, -2318],
      "size": [329, 425],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [325]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": ["example.png", "image"]
    },
    {
      "id": 159,
      "type": "ImageScale",
      "pos": [-2450, -2318],
      "size": [315, 130],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "link": 325
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [302, 326]
        }
      ],
      "title": "Scale to Max 1024 (Keep Ratio)",
      "properties": {
        "Node name for S&R": "ImageScale"
      },
      "widgets_values": [
        "lanczos",
        1024,
        1024,
        "disabled"
      ],
      "color": "#323",
      "bgcolor": "#535"
    },
    {
      "id": 82,
      "type": "MarkdownNote",
      "pos": [-3836, -2318],
      "size": [684, 950],
      "flags": {},
      "order": 2,
      "mode": 0,
      "title": "Optimized Fast Version",
      "properties": {},
      "widgets_values": [
        "## Extreme Speed Optimization\n\nScaling Strategy:\n- Input: Any size (e.g., 2048x1536)\n- Processing: Max 1024 (e.g., 1024x768, keep ratio)\n- Output: Max 1024 (save at processing size)\n\nExamples:\n- 2048x2048 -> 1024x1024 -> Save 1024x1024\n- 2048x1536 -> 1024x768 -> Save 1024x768\n- 1600x900 -> 1024x576 -> Save 1024x576\n- 800x600 -> 800x600 -> Save 800x600 (no upscale)\n\nPerformance Optimizations:\n- Single TextEncodeQwenImageEditPlus (no negative)\n- 4 steps Lightning LoRA\n- CFG = 1.5\n- FP8 CLIP (faster than BF16)\n- No Switch nodes\n- No FluxKontextMultiReference\n\nExpected Performance (A100):\n- First run: 12-15s (with model loading)\n- Subsequent runs: 6-8s\n\nSpeed Comparison:\n- Input 2048x2048: 23s\n- Input 1024x1024: 6-8s\n- Scaling saves 3x time!\n\nModel Files:\n- qwen_image_edit_2511_bf16.safetensors\n- qwen_2.5_vl_7b_fp8_scaled.safetensors (FP8 recommended)\n- qwen_image_vae.safetensors\n- Qwen-Image-Edit-2511-Lightning-4steps-V1.0-bf16.safetensors"
      ],
      "color": "#222",
      "bgcolor": "#000"
    },
    {
      "id": 9,
      "type": "SaveImage",
      "pos": [-806, -2318],
      "size": [696, 486],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 320
        }
      ],
      "outputs": [],
      "properties": {
        "Node name for S&R": "SaveImage"
      },
      "widgets_values": ["Qwen_Edit_Fast"]
    },
    {
      "id": 150,
      "type": "UNETLoader",
      "pos": [-2180, -2318],
      "size": [320, 82],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [313]
        }
      ],
      "properties": {
        "Node name for S&R": "UNETLoader"
      },
      "widgets_values": ["qwen_image_edit_2511_bf16.safetensors", "default"]
    },
    {
      "id": 151,
      "type": "CLIPLoader",
      "pos": [-2180, -2200],
      "size": [320, 82],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [314, 324]
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPLoader"
      },
      "widgets_values": ["qwen_2.5_vl_7b.safetensors", "qwen_image", "default"]
    },
    {
      "id": 152,
      "type": "VAELoader",
      "pos": [-2180, -2082],
      "size": [320, 58],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [315, 316, 319]
        }
      ],
      "properties": {
        "Node name for S&R": "VAELoader"
      },
      "widgets_values": ["qwen_image_vae.safetensors"]
    },
    {
      "id": 153,
      "type": "LoraLoaderModelOnly",
      "pos": [-1810, -2318],
      "size": [320, 82],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 313
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [317]
        }
      ],
      "properties": {
        "Node name for S&R": "LoraLoaderModelOnly"
      },
      "widgets_values": ["Qwen-Image-Edit-2511-Lightning-4steps-V1.0-bf16.safetensors", 1]
    },
    {
      "id": 154,
      "type": "TextEncodeQwenImageEditPlus",
      "pos": [-1810, -2200],
      "size": [320, 150],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 314
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 315
        },
        {
          "name": "image1",
          "type": "IMAGE",
          "link": 302
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [318]
        }
      ],
      "title": "Prompt Encode (Positive Only)",
      "properties": {
        "Node name for S&R": "TextEncodeQwenImageEditPlus"
      },
      "widgets_values": ["Change the style to modern design. Keep the original composition."],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 158,
      "type": "CLIPTextEncode",
      "pos": [-1810, -2000],
      "size": [320, 100],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 324
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [323]
        }
      ],
      "title": "Empty Negative Prompt",
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [""]
    },
    {
      "id": 155,
      "type": "VAEEncode",
      "pos": [-1450, -2318],
      "size": [210, 46],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "pixels",
          "type": "IMAGE",
          "link": 326
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 316
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [321]
        }
      ],
      "properties": {
        "Node name for S&R": "VAEEncode"
      },
      "widgets_values": []
    },
    {
      "id": 156,
      "type": "KSampler",
      "pos": [-1200, -2318],
      "size": [315, 262],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 317
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 318
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 323
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 321
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [322]
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        123456789,
        "randomize",
        4,
        1.5,
        "euler",
        "simple",
        1
      ]
    },
    {
      "id": 157,
      "type": "VAEDecode",
      "pos": [-1200, -2010],
      "size": [210, 46],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 322
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 319
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [320]
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      },
      "widgets_values": []
    }
  ],
  "links": [
    [302, 159, 0, 154, 2, "IMAGE"],
    [313, 150, 0, 153, 0, "MODEL"],
    [314, 151, 0, 154, 0, "CLIP"],
    [315, 152, 0, 154, 1, "VAE"],
    [316, 152, 0, 155, 1, "VAE"],
    [317, 153, 0, 156, 0, "MODEL"],
    [318, 154, 0, 156, 1, "CONDITIONING"],
    [319, 152, 0, 157, 1, "VAE"],
    [320, 157, 0, 9, 0, "IMAGE"],
    [321, 155, 0, 156, 3, "LATENT"],
    [322, 156, 0, 157, 0, "LATENT"],
    [323, 158, 0, 156, 2, "CONDITIONING"],
    [324, 151, 0, 158, 0, "CLIP"],
    [325, 41, 0, 159, 0, "IMAGE"],
    [326, 159, 0, 155, 0, "IMAGE"]
  ],
  "groups": [],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.8,
      "offset": [2820, 2318]
    }
  },
  "version": 0.4
}
