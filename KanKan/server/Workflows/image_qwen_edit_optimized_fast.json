{
  "9": {
    "inputs": {
      "filename_prefix": "Qwen_Edit_Fast",
      "images": [
        "157",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "41": {
    "inputs": {
      "image": "f3.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "150": {
    "inputs": {
      "unet_name": "qwen_image_edit_2511_bf16.safetensors",
      "weight_dtype": "default"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "151": {
    "inputs": {
      "clip_name": "qwen_2.5_vl_7b.safetensors",
      "type": "qwen_image",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "152": {
    "inputs": {
      "vae_name": "qwen_image_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "153": {
    "inputs": {
      "lora_name": "Qwen-Image-Edit-2511-Lightning-4steps-V1.0-bf16.safetensors",
      "strength_model": 1,
      "model": [
        "150",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "154": {
    "inputs": {
      "prompt": "The face is crying",
      "clip": [
        "151",
        0
      ],
      "vae": [
        "152",
        0
      ],
      "image1": [
        "159",
        0
      ]
    },
    "class_type": "TextEncodeQwenImageEditPlus",
    "_meta": {
      "title": "Prompt Encode (Positive Only)"
    }
  },
  "155": {
    "inputs": {
      "pixels": [
        "159",
        0
      ],
      "vae": [
        "152",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "156": {
    "inputs": {
      "seed": 0,
      "steps": 4,
      "cfg": 1.5,
      "sampler_name": "euler",
      "scheduler": "simple",
      "denoise": 1,
      "model": [
        "153",
        0
      ],
      "positive": [
        "154",
        0
      ],
      "negative": [
        "158",
        0
      ],
      "latent_image": [
        "155",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "157": {
    "inputs": {
      "samples": [
        "156",
        0
      ],
      "vae": [
        "152",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "158": {
    "inputs": {
      "text": "",
      "clip": [
        "151",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "Empty Negative Prompt"
    }
  },
  "159": {
    "inputs": {
      "upscale_method": "lanczos",
      "width": 1024,
      "height": 1024,
      "crop": "disabled",
      "image": [
        "41",
        0
      ]
    },
    "class_type": "ImageScale",
    "_meta": {
      "title": "Scale to Max 1024 (Keep Ratio)"
    }
  }
}
